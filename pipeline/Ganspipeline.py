{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9ee261a-e3b0-40fc-a9cd-49a5a0d8d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Database connection\n",
    "schema = \"citiesforgans\"\n",
    "host = \"127.0.0.1\"\n",
    "user = \"root\"\n",
    "password = \"*****\"\n",
    "port = 3306\n",
    "connection_string = f'mysql+pymysql://{user}:{password}@{host}:{port}/{schema}'\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "def complete_weather_flight_pipeline(Citylist):\n",
    "    data = \"\"\"\n",
    "    200 Thunderstorm with light rain\n",
    "    201 Thunderstorm with rain\n",
    "    202 Thunderstorm with heavy rain\n",
    "    210 Light thunderstorm\n",
    "    211 Thunderstorm\n",
    "    212 Heavy thunderstorm\n",
    "    221 Ragged thunderstorm\n",
    "    230 Thunderstorm with light drizzle\n",
    "    231 Thunderstorm with drizzle\n",
    "    232 Thunderstorm with heavy drizzle\n",
    "    300 Light intensity drizzle\n",
    "    301 Drizzle\n",
    "    302 Heavy intensity drizzle\n",
    "    310 Light intensity drizzle rain\n",
    "    311 Drizzle rain\n",
    "    312 Heavy intensity drizzle rain\n",
    "    313 Shower rain and drizzle\n",
    "    314 Heavy shower rain and drizzle\n",
    "    321 Shower drizzle\n",
    "    500 Light rain\n",
    "    501 Moderate rain\n",
    "    502 Heavy intensity rain\n",
    "    503 Very heavy rain\n",
    "    504 Extreme rain\n",
    "    511 Freezing rain\n",
    "    520 Light intensity shower rain\n",
    "    521 Shower rain\n",
    "    522 Heavy intensity shower rain\n",
    "    531 Ragged shower rain\n",
    "    600 Light snow\n",
    "    601 Snow\n",
    "    602 Heavy snow\n",
    "    611 Sleet\n",
    "    612 Light shower sleet\n",
    "    613 Shower sleet\n",
    "    615 Light rain and snow\n",
    "    616 Rain and snow\n",
    "    620 Light shower snow\n",
    "    621 Shower snow\n",
    "    622 Heavy shower snow\n",
    "    701 Mist\n",
    "    711 Smoke\n",
    "    721 Haze\n",
    "    731 Sand/dust whirls\n",
    "    741 Fog\n",
    "    751 Sand\n",
    "    761 Dust\n",
    "    762 Volcanic ash\n",
    "    771 Squalls\n",
    "    781 Tornado\n",
    "    800 Clear sky\n",
    "    801 Few clouds: 11-25%\n",
    "    802 Scattered clouds: 25-50%\n",
    "    803 Broken clouds: 51-84%\n",
    "    804 Overcast clouds: 85-100%\n",
    "    \"\"\"\n",
    "\n",
    "    lines = data.strip().split('\\n')\n",
    "    weather_id = []\n",
    "    description = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = line.split(' ', 1)\n",
    "        if len(parts) == 2 and parts[0].isdigit():\n",
    "            weather_id.append(int(parts[0]))\n",
    "            description.append(parts[1].strip())\n",
    "\n",
    "    desc_df = pd.DataFrame({\n",
    "        'Weatherid': weather_id,\n",
    "        'Description_': description\n",
    "    })\n",
    "\n",
    "    desc_sql = pd.read_sql('weatherdescription', con=connection_string)\n",
    "    desc_df = desc_df.loc[~(desc_df['Weatherid'].isin(desc_sql['Weatherid'])), :]\n",
    "    desc_df.to_sql('weatherdescription', if_exists='append', con=connection_string, index=False)\n",
    "\n",
    "    def Cityinfo(cities):\n",
    "        City, latitude, longitude, country, Population, Timestamp = [], [], [], [], [], []\n",
    "\n",
    "        for c in cities:\n",
    "            url = f'https://en.wikipedia.org/wiki/{c}'\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            lat_tags = soup.find_all(class_='latitude')\n",
    "            lon_tags = soup.find_all(class_='longitude')\n",
    "\n",
    "            if not lat_tags or not lon_tags:\n",
    "            \n",
    "             continue\n",
    "\n",
    "            latitudec = lat_tags[0].get_text()\n",
    "            longitudec = lon_tags[0].get_text()\n",
    "\n",
    "            countryc = soup.find_all(class_='infobox-data')[0].get_text()\n",
    "            populationc = soup.find(string='Population').find_next('td').get_text()\n",
    "            populationclean = populationc.replace(',', '')\n",
    "            populationcleaner = re.sub(r\"\\D\", \"\", populationclean)\n",
    "            populationapp = int(populationcleaner)\n",
    "            todayc = datetime.today().strftime('%Y')\n",
    "\n",
    "            City.append(c)\n",
    "            latitude.append(latitudec)\n",
    "            longitude.append(longitudec)\n",
    "            country.append(countryc)\n",
    "            Population.append(populationapp)\n",
    "            Timestamp.append(todayc)\n",
    "\n",
    "        return pd.DataFrame({\n",
    "            'City': City,\n",
    "            'Latitude': latitude,\n",
    "            'Longitude': longitude,\n",
    "            'Country': country,\n",
    "            'Population': Population,\n",
    "            'Timestamp': Timestamp\n",
    "        })\n",
    "\n",
    "    cities = Citylist\n",
    "    Cityinfo_df = Cityinfo(cities)\n",
    "    Cityinfo_df['Timestamp'] = pd.to_datetime(Cityinfo_df['Timestamp'])\n",
    "    Citydetails_df = Cityinfo_df.copy()\n",
    "    Citydetails_df['YearRetrieved'] = Citydetails_df['Timestamp'].dt.year\n",
    "    Citydetails_df = Citydetails_df.drop(columns='Timestamp')\n",
    "    City_ser = Citydetails_df['City']\n",
    "\n",
    "    City_sql = pd.read_sql('city', con=connection_string)\n",
    "    City_ser = City_ser.loc[~(City_ser.isin(City_sql['City']))]\n",
    "    City_ser.to_sql('city', if_exists='append', con=connection_string, index=False)\n",
    "    City_sql = pd.read_sql('city', con=connection_string)\n",
    "    Citydetails = Citydetails_df.merge(City_sql, on='City', how='right')\n",
    "    cols = Citydetails.columns.tolist()\n",
    "    cols.insert(0, cols.pop(cols.index('Cityid')))\n",
    "    Citydetails = Citydetails[cols]\n",
    "    Citydetails = Citydetails.drop(columns='City')\n",
    "    Citydetails_sql = pd.read_sql('citydetails', con=connection_string)\n",
    "    Citydetails = Citydetails.loc[~(Citydetails['Cityid'].isin(Citydetails_sql['Cityid'])), :]\n",
    "\n",
    "    def dms_to_decimal(dms_str):\n",
    "        dms_str = dms_str.strip()\n",
    "        try:\n",
    "            return float(dms_str)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        pattern = r'^(\\d+)[°\\s]*(?:(\\d+)[\\'′\\s]*)?(?:(\\d+)[\\\"″\\s]*)?([NSEW])$'\n",
    "        match = re.match(pattern, dms_str, re.IGNORECASE)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Invalid DMS format: {dms_str}\")\n",
    "        degrees = int(match.group(1))\n",
    "        minutes = int(match.group(2)) if match.group(2) else 0\n",
    "        seconds = int(match.group(3)) if match.group(3) else 0\n",
    "        direction = match.group(4).upper()\n",
    "        decimal = degrees + minutes / 60 + seconds / 3600\n",
    "        if direction in ['S', 'W']:\n",
    "            decimal *= -1\n",
    "        return decimal\n",
    "\n",
    "    Citydetails['Longitude'] = round(Citydetails['Longitude'].apply(dms_to_decimal), 2)\n",
    "    Citydetails['Latitude'] = round(Citydetails['Latitude'].apply(dms_to_decimal), 2)\n",
    "    Citydetails.to_sql('citydetails', if_exists='append', con=connection_string, index=False)\n",
    "\n",
    "    Citydetails_df = pd.read_sql('citydetails', con=connection_string)\n",
    "    City_df = pd.read_sql('city', con=connection_string)\n",
    "    Citiesmerge = Citydetails_df.merge(City_df, on='Cityid')\n",
    "\n",
    "    latitude = Citiesmerge['Latitude']\n",
    "    longitude = Citiesmerge['Longitude']\n",
    "    Cities = Citiesmerge['City']\n",
    "    Cityid = Citiesmerge['Cityid']\n",
    "\n",
    "    Weather, Weatherid, Temperature, Feelslike = [], [], [], []\n",
    "    Humidity, Wind, Datetime_, Cityname = [], [], [], []\n",
    "    Cityids, Dateretrieved = [], []\n",
    "\n",
    "    for city, lat, lon, city_id in zip(Cities, latitude, longitude, Cityid):\n",
    "        url = 'https://api.openweathermap.org/data/2.5/forecast?'\n",
    "        api_key = 'f1faf8c6c48d6389a3872306f7d0e886'\n",
    "        querystring = {'lat': lat, 'lon': lon, 'appid': api_key, 'units': 'metric'}\n",
    "        city_request = requests.get(url, params=querystring).json()['list']\n",
    "        for i in city_request:\n",
    "            Cityids.append(city_id)\n",
    "            Cityname.append(city)\n",
    "            Weatherid.append(i['weather'][0]['id'])\n",
    "            Weather.append(i['weather'][0]['main'])\n",
    "            Temperature.append(i['main']['temp'])\n",
    "            Feelslike.append(i['main']['feels_like'])\n",
    "            Humidity.append(i['main']['humidity'])\n",
    "            Wind.append(i['wind']['speed'])\n",
    "            Datetime_.append(i['dt_txt'])\n",
    "            Dateretrieved.append(pd.Timestamp.now().strftime('%Y-%m-%d-%H:%M'))\n",
    "\n",
    "    Weather_df = pd.DataFrame({\n",
    "        'Cityid': Cityids,\n",
    "        'Weatherid': Weatherid,\n",
    "        'Weather': Weather,\n",
    "        'Temperature': Temperature,\n",
    "        'Feelslike': Feelslike,\n",
    "        'Humidity': Humidity,\n",
    "        'Wind': Wind,\n",
    "        'Dateandtime': Datetime_,\n",
    "        'Dateretrieved': Dateretrieved\n",
    "    })\n",
    "\n",
    "    Weather_sql = pd.read_sql('weather', con=connection_string)\n",
    "    Weather_df['Dateandtime'] = pd.to_datetime(Weather_df['Dateandtime'])\n",
    "    Weather_sql['Dateandtime'] = pd.to_datetime(Weather_sql['Dateandtime'])\n",
    "    Weather_df = Weather_df.loc[~(Weather_df['Cityid'].isin(Weather_sql['Cityid'])), :]\n",
    "    Weather_df.to_sql('weather', if_exists='append', con=connection_string, index=False)\n",
    "\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(\"DELETE FROM weather WHERE Dateandtime < NOW()\"))\n",
    "        conn.commit()\n",
    "    Weather_df = pd.read_sql('weather', con=connection_string)\n",
    "\n",
    "    Citydetails_air = pd.read_sql('citydetails', con=connection_string)\n",
    "    Latitude_air = Citydetails_air['Latitude']\n",
    "    Longitude_air = Citydetails_air['Longitude']\n",
    "    Cityid_air = Citydetails_air['Cityid']\n",
    "\n",
    "    Airport, Icao, Cityid = [], [], []\n",
    "\n",
    "    for Cityids, Latitude, Longitude in zip(Cityid_air, Latitude_air, Longitude_air):\n",
    "        url = 'https://aerodatabox.p.rapidapi.com/airports/search/location?'\n",
    "        querystring_air = {'lat': Latitude, 'lon': Longitude, 'radiusKm': 50, 'limit': 10, 'withFlightInfoOnly': 'true'}\n",
    "        header_air = {\n",
    "            'x-rapidapi-host': 'aerodatabox.p.rapidapi.com',\n",
    "            'x-rapidapi-key': '687292277emsh6620811a3972b04p1a4ee9jsn8c02f9bc139b'\n",
    "        }\n",
    "        airport_request = requests.get(url, params=querystring_air, headers=header_air).json()\n",
    "        airport_count = airport_request['count']\n",
    "        for i in range(airport_count):\n",
    "            Air_loop = airport_request['items'][i]['name']\n",
    "            Icao_loop = airport_request['items'][i]['icao']\n",
    "            Airport.append(Air_loop)\n",
    "            Icao.append(Icao_loop)\n",
    "            Cityid.append(Cityids)\n",
    "\n",
    "    Airport_df = pd.DataFrame({'Cityid': Cityid, 'Airport': Airport, 'ICAO': Icao})\n",
    "    Airport_sql = pd.read_sql('airport', con=connection_string)\n",
    "    Airport_df = Airport_df.loc[~(Airport_df['ICAO'].isin(Airport_sql['ICAO'])), :]\n",
    "    Airport_df.to_sql('airport', if_exists='append', con=connection_string, index=False)\n",
    "    Airport_df = pd.read_sql('airport', con=connection_string)\n",
    "\n",
    "    Origincity, Arrivaltime, Airline, Flightnumber = [], [], [], []\n",
    "    Terminal, ICAO, Timeretrieved = [], [], []\n",
    "\n",
    "    Icao_fl = Airport_df['ICAO']\n",
    "    cur_day = pd.Timestamp.now().date()\n",
    "    next_day_fh = pd.to_datetime(f'{cur_day.year}-{cur_day.month}-{cur_day.day + 1}-00:00')\n",
    "    next_day_sh = pd.to_datetime(f'{cur_day.year}-{cur_day.month}-{cur_day.day + 1}-12:00')\n",
    "    next_day = [next_day_fh, next_day_sh]\n",
    "\n",
    "    for Icao_code in Icao_fl:\n",
    "        for nday in next_day:\n",
    "            loop_hour = (nday.hour + 11)\n",
    "            loop_minute = 59\n",
    "            url = (\n",
    "                f'https://aerodatabox.p.rapidapi.com/flights/airports/icao/'\n",
    "                f'{Icao_code}/{nday.year}-{nday.month:02d}-{nday.day:02d}T{nday.hour:02d}:{nday.minute:02d}/'\n",
    "                f'{nday.year}-{nday.month:02d}-{nday.day:02d}T{loop_hour:02d}:{loop_minute:02d}?'\n",
    "            )\n",
    "            querystring_fl = {\n",
    "                'withLeg': 'false',\n",
    "                'direction': 'Arrival',\n",
    "                'withCancelled': 'false',\n",
    "                'withCargo': 'false',\n",
    "                'withCodeshared': 'false',\n",
    "                'withPrivate': 'false',\n",
    "                'withLocation': 'false'\n",
    "            }\n",
    "            header_fl = {\n",
    "                'x-rapidapi-host': 'aerodatabox.p.rapidapi.com',\n",
    "                'x-rapidapi-key': '687292277emsh6620811a3972b04p1a4ee9jsn8c02f9bc139b'\n",
    "            }\n",
    "            flight_request_raw = requests.get(url, params=querystring_fl, headers=header_fl)\n",
    "            try:\n",
    "                flight_request = flight_request_raw.json()\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "            if not flight_request or 'arrivals' not in flight_request or not flight_request['arrivals']:\n",
    "                continue\n",
    "            for i in range(len(flight_request['arrivals'])):\n",
    "                movement_loop = flight_request['arrivals'][i]['movement']\n",
    "                origincity = movement_loop['airport']['name']\n",
    "                arrivaltime = movement_loop.get('revisedTime', {}).get('local') or movement_loop.get('scheduledTime', {}).get('local')\n",
    "                airline = flight_request['arrivals'][i]['airline']['name']\n",
    "                terminal = movement_loop.get('terminal', 1)\n",
    "                flightnumber = flight_request['arrivals'][i]['number']\n",
    "\n",
    "                ICAO.append(Icao_code)\n",
    "                Origincity.append(origincity)\n",
    "                Arrivaltime.append(arrivaltime)\n",
    "                Airline.append(airline)\n",
    "                Terminal.append(terminal)\n",
    "                Flightnumber.append(flightnumber)\n",
    "                Timeretrieved.append(pd.Timestamp.now().strftime('%Y-%m-%d-%H:%M'))\n",
    "\n",
    "    Flights_df = pd.DataFrame({\n",
    "        'ICAO': ICAO,\n",
    "        \"Origincity\": Origincity,\n",
    "        'Airline': Airline,\n",
    "        'Flightnumber': Flightnumber,\n",
    "        'Terminal': Terminal,\n",
    "        \"Arrivaltime\": Arrivaltime,\n",
    "        'Timeretrieved': Timeretrieved\n",
    "    })\n",
    "\n",
    "    Flights_df['Arrivaltime'] = Flights_df['Arrivaltime'].str.replace(r'\\+.*$', '', regex=True)\n",
    "    Flights_df['Arrivaltime'] = pd.to_datetime(Flights_df['Arrivaltime'])\n",
    "    Flights_df['Timeretrieved'] = pd.to_datetime(Flights_df['Timeretrieved'])\n",
    "    Flights_sql = pd.read_sql('flights', con=connection_string)\n",
    "    Flights_df = Flights_df.loc[~(Flights_df['Flightnumber'].isin(Flights_sql['Flightnumber'])), :]\n",
    "    Flights_df.to_sql('flights', if_exists='append', con=connection_string, index=False)\n",
    "\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(\"DELETE FROM flights WHERE arrivaltime < NOW()\"))\n",
    "        conn.commit()\n",
    "    Flights_df = pd.read_sql('flights', con=connection_string)\n",
    "\n",
    "\n",
    "    \n",
    "Citylist = ['Berlin','Hamburg','Munich','Leipzig','Kassel','Vienna','Stuttgart','Paris','Zurich','Madrid','Dortmund','Copenhagen', 'Oslo']\n",
    "\n",
    "complete_weather_flight_pipeline(Citylist)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
